{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ランダムフォレストは、アンサンブル学習のひとつです。\n",
    "#アンサンブル学習とは、複数の学習機を組み合わせてより良い予測を得ようとするテクニック\n",
    "\n",
    "#どのように複数の学習器を組み合わせるのかというと、分類の場合は複数の学習器の多数決をとり、回帰の場合は複数の学習器の平均をとります。\n",
    "\n",
    "#アンサンブル学習においてよく用いられるテクニックとして、バギングやブースティング、スタッキングやバンピングなどがあります。\n",
    "\n",
    "#ランダムフォレストは、この中でもバギングというテクニックを用いて、行う事象\n",
    "#Bagging(バギング)は、bootstrap aggregatingの略です。\n",
    "\n",
    "#ブーストトラップというテクニックを用いて、一つのデータセットからいくつものデータセットを作成し、その複製したデータセット一つにつき一つの学習器を生成し、\n",
    "#そのようにして作成した複数の学習器の多数決を行うことで最終的な予測を行います。\n",
    "\n",
    "\n",
    "#アルゴリズムは以下のようになります。\n",
    "\n",
    "1訓練データからN個のブーストトラップデータ集合を作成する。\n",
    "\n",
    "2このデータ集合を用いてN個の決定木を生成する。この時、p個の特徴量からm個の特徴量をランダムに選ぶ。\n",
    "\n",
    "3分類の場合はN個の決定木の多数決を、回帰の場合はN個の決定木の予測の平均を最終的な予測とする。\n",
    "\n",
    "\n",
    "#イメージとしては　同じような人がたくさん集まるよりも、違う考えの人が集まったほうが良い結論が出る。\n",
    "\n",
    "それは、アンサンブル学習においてはモデル間の相関が低ければ低いほど予測値の精度は高まるからです。\n",
    "フローチャート　を木と呼ぶ\n",
    "\n",
    "ランダムフォレストはたくさんのフローチャートを作成し、　それぞれの木に予測させ、\n",
    "その結果の多数決で、最終結果を求める方式\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 決定木\n",
    "\n",
    "#決定木は、条件分岐によってグループを分割して分類する手法です。その際にグループがなるべく同じような属性で構成されるように分割します。下の画像を見るとより理解しやすいと思います。\n",
    "\n",
    "#このように条件分岐を繰り返すことで、データはツリー状にどんどん展開され、解くべき最小単位に分割されていきます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ランダムフォレストのように様々な予測モデルを作成し、最終的に１つの答えをだすことを\n",
    "アンサンブル学習という"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,t,test_size =0.2,random_state = 0)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 200,\n",
    "                              random_state = 0) #estimatorsは作成する木の数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-1-e7911b5bf10a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-e7911b5bf10a>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    モデル変数　＝\u001b[0m\n\u001b[1;37m         　^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "モデル変数　＝RandomForestClassifier(n_estimators = 〇　木の数,random_state=〇,max_depth〇）\n",
    "                              \n",
    "           #ランダムフォレストのインポート                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train)\n",
    "\n",
    "print (model.score(x_train,y_train))\n",
    "print(model.score(x_test,y_test))\n",
    "\n",
    "#モデルの学習\n",
    "\n",
    "0.9887640449438202\n",
    "0.8715083798882681"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "model2 = tree.DecisionTreeclassifier(random = state = 0)\n",
    "model2.fit (x_train,y_train)\n",
    "\n",
    "print(model2.score(x_train,y_train))\n",
    "print (model2.score(x_test,y_test))\n",
    "#単純な決定木の結果\n",
    "\n",
    "0.9887640449438202\n",
    "0.8156424581005587"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ランダムフォレストの良いところは、決定木と比べると、過学習をふせぐことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#それぞれ異なった方向に過学習している決定木をたくさん作り、その平均をとることで　\n",
    "過学習の度合いをへらすことができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGブースト\n",
    "#XGブーストとは、一つの学習機を強化し、せいのうをさらに高める技術のことである・"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
